import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";
import fs from "fs";
import path from "path";
import os from "os";

// ============================================
// ğŸ“Œ STT API - Speech-to-Text Transcription
// ============================================
// POST /api/transcribe
// - ìŒì„± íŒŒì¼ì„ ë°›ì•„ì„œ OpenAI Whisper APIë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
// - ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜ (Vercel serverless í™˜ê²½ìš©)
//
// í…ŒìŠ¤íŠ¸ ëª¨ë“œ: .env.localì— TEST_MODE=true ì¶”ê°€ ì‹œ
// OpenAI API í˜¸ì¶œ ì—†ì´ ëª¨ì˜(mock) ì‘ë‹µ ë°˜í™˜

// TEST_MODEê°€ í™œì„±í™”ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const TEST_MODE = process.env.TEST_MODE === "true";
const openai = TEST_MODE
  ? null
  : new OpenAI({
      apiKey: process.env.OPENAI_API_KEY || process.env.OPENAI_KEY,
    });

export async function POST(request: NextRequest) {
  let tempFilePath: string | null = null;

  try {
    // 1. FormDataì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    const formData = await request.formData();
    const audioFile = formData.get("audio") as File;

    if (!audioFile) {
      return NextResponse.json({ error: "ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤." }, { status: 400 });
    }

    // 2. File ê°ì²´ë¥¼ Bufferë¡œ ë³€í™˜
    const arrayBuffer = await audioFile.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    let transcriptionText: string;

    // 3. OpenAI Whisper APIë¡œ ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜ (ë˜ëŠ” í…ŒìŠ¤íŠ¸ ëª¨ë“œ)
    if (TEST_MODE) {
      // í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ëª¨ì˜ ì‘ë‹µ ë°˜í™˜
      console.log("ğŸ§ª TEST_MODE: OpenAI API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°");
      transcriptionText =
        "[í…ŒìŠ¤íŠ¸ ëª¨ë“œ] ì´ê²ƒì€ ëª¨ì˜ ìŒì„± ë³€í™˜ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ TEST_MODEë¥¼ falseë¡œ ì„¤ì •í•˜ê³  ìœ íš¨í•œ API í‚¤ì™€ í¬ë ˆë”§ì„ í™•ì¸í•˜ì„¸ìš”.";
    } else {
      // ì‹¤ì œ OpenAI API í˜¸ì¶œ
      if (!openai) {
        throw new Error("OpenAI client is not initialized");
      }

      // Vercel serverless í™˜ê²½ì—ì„œëŠ” /tmp ë””ë ‰í† ë¦¬ ì‚¬ìš©
      const tempDir = os.tmpdir();
      tempFilePath = path.join(tempDir, `audio_${Date.now()}.wav`);

      // ì„ì‹œ íŒŒì¼ ì €ì¥ (OpenAI APIëŠ” íŒŒì¼ ìŠ¤íŠ¸ë¦¼ í•„ìš”)
      fs.writeFileSync(tempFilePath, buffer);

      const transcription = await openai.audio.transcriptions.create({
        model: "whisper-1",
        file: fs.createReadStream(tempFilePath),
        language: "ko",
      });

      transcriptionText = transcription.text;
    }

    // 4. ê²°ê³¼ ë°˜í™˜ (íŒŒì¼ ì €ì¥ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜)
    return NextResponse.json({
      success: true,
      text: transcriptionText,
      timestamp: new Date().toISOString(),
      testMode: TEST_MODE,
    });
  } catch (error) {
    console.error("Transcription error:", error);

    return NextResponse.json(
      {
        error: "ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        details: error instanceof Error ? error.message : "Unknown error",
      },
      { status: 500 },
    );
  } finally {
    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (tempFilePath && fs.existsSync(tempFilePath)) {
      try {
        fs.unlinkSync(tempFilePath);
      } catch (err) {
        console.error("ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨:", err);
      }
    }
  }
}
