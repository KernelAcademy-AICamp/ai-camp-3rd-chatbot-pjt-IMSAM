import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";
import fs from "fs";
import path from "path";
import os from "os";

// ============================================
// ğŸ“Œ STT API - Speech-to-Text Transcription
// ============================================
// POST /api/transcribe
// - ìŒì„± íŒŒì¼ì„ ë°›ì•„ì„œ OpenAI Whisper APIë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
// - ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜ (Vercel serverless í™˜ê²½ìš©)
//
// í…ŒìŠ¤íŠ¸ ëª¨ë“œ: .env.localì— TEST_MODE=true ì¶”ê°€ ì‹œ
// OpenAI API í˜¸ì¶œ ì—†ì´ ëª¨ì˜(mock) ì‘ë‹µ ë°˜í™˜

// TEST_MODEê°€ í™œì„±í™”ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const TEST_MODE = process.env.TEST_MODE === "true";
const openai = TEST_MODE
  ? null
  : new OpenAI({
      apiKey: process.env.OPENAI_API_KEY || process.env.OPENAI_KEY,
    });

export async function POST(req: NextRequest) {
  try {
        // 1. FormDataì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    const formData = await req.formData();
    const audioFile = formData.get("audio") as File;

    if (!audioFile) {
      return NextResponse.json({ error: "ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤." }, { status: 400 });
    }

    // 2. File ê°ì²´ë¥¼ Bufferë¡œ ë³€í™˜
    const arrayBuffer = await audioFile.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    let transcriptionText: string = "";

    // 3. OpenAI Whisper APIë¡œ ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜ (ë˜ëŠ” í…ŒìŠ¤íŠ¸ ëª¨ë“œ)
    if (TEST_MODE) {
      // í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ëª¨ì˜ ì‘ë‹µ ë°˜í™˜
      console.log("ğŸ§ª TEST_MODE: OpenAI API í˜¸ì¶œ ê±´ë„ˆë›°ê¸°");
      transcriptionText =
        "[í…ŒìŠ¤íŠ¸ ëª¨ë“œ] ì´ê²ƒì€ ëª¨ì˜ ìŒì„± ë³€í™˜ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ TEST_MODEë¥¼ falseë¡œ ì„¤ì •í•˜ê³  ìœ íš¨í•œ API í‚¤ì™€ í¬ë ˆë”§ì„ í™•ì¸í•˜ì„¸ìš”.";
    } else {
      // ì‹¤ì œ OpenAI API í˜¸ì¶œ
      if (!openai) {
        throw new Error("OpenAI client is not initialized");
      }

      const transcription = await openai!.audio.transcriptions.create({
        model: "whisper-1",
        file: new File([buffer], "audio.wav", { type: "audio/wav" }),
        language: "ko",
      });

      transcriptionText = transcription.text;
    }

    // 4. ê²°ê³¼ ë°˜í™˜ (íŒŒì¼ ì €ì¥ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜)
    return NextResponse.json({
      success: true,
      text: transcriptionText,
      timestamp: new Date().toISOString(),
      testMode: TEST_MODE,
    });
  } catch (err: any) {
    console.error("STT Error:", err);

    return NextResponse.json(
      {
        error: "ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
        details: err.message || err,
      },
      { status: 500 },
    );
  }
}
